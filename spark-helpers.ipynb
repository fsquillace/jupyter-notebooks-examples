{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def spark_session(app_name):\n",
    "    return SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(app_name) \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "def convert_to_df(values, attr_names=None):\n",
    "    \"\"\"\n",
    "    Converts either a list of dict or a list of tuples to a Spark DataFrame.\n",
    "    \n",
    "    Acceptable types for values are (mapped to the spark types in pyspark.sql.types):\n",
    "\n",
    "    - bool\n",
    "    - int, long\n",
    "    - float, decimal.Decimal\n",
    "    - str, unicode\n",
    "    - bytearray\n",
    "    - datetime.date, datetime.datetime\n",
    "    - list, tuple, array\n",
    "    - dict    \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    values : list of dict or list of tuple\n",
    "        A list of dict to be converted as list of pyspark.sql.Row. The dict must\n",
    "        contain str as keys (will be the Data frame attribute name) and simple types\n",
    "        as values (the accepted types are listed above).\n",
    "        Every dict must contain the exact same keys and value types.\n",
    "        \n",
    "        A list of tuple to be converted as list of pyspark.sql.Row. attr_names is required in this case.\n",
    "        The tuple content must contain simple types as values (the accepted types are listed above).\n",
    "        Every tuple must contain the exact value types and size must be the same as attr_names.\n",
    "        \n",
    "    attr_names : list of str\n",
    "        If values is a list of tuple, attr_names contains the corresponding attribute names.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        pyspark.sql.dataframe.DataFrame\n",
    "        \n",
    "    Examples:\n",
    "    --------\n",
    "    To convert a list of dict:\n",
    "    \n",
    "    ```\n",
    "    convert_to_df([{'Person': 'Eric', 'Age': 31}, {'Person': 'Laura', 'Age': 29}])\n",
    "    ```\n",
    "        \n",
    "    To convert a list of tuples:\n",
    "    \n",
    "    ```\n",
    "    convert_to_df([('Eric', 31), ('Laura', 29)], attr_names=['Person', 'Age'])\n",
    "    ```\n",
    "    \"\"\"\n",
    "    if attr_names is not None:\n",
    "        SparkRow = Row(*attr_names)\n",
    "        def _convert_to_row(d):\n",
    "            return SparkRow(*d)\n",
    "    else:\n",
    "        def _convert_to_row(d):\n",
    "            return Row(**d)\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    return sc.parallelize(values).map(_convert_to_row).toDF()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
